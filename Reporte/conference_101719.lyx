#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsfonts}
\usepackage{amsfonts}\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\end_preamble
\options conference
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Driver behavior and Machine Learning
\begin_inset Newline newline
\end_inset

 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Identify applicable funding agency here.
 If none, delete this.
\end_layout

\end_inset

 
\end_layout

\begin_layout Author
\begin_inset Flex Author Name
status collapsed

\begin_layout Plain Layout
Emilio Tonix Gleason
\end_layout

\end_inset

 
\begin_inset Flex Author Affiliation
status collapsed

\begin_layout Plain Layout

\shape italic
dept of computer Science
\shape default

\begin_inset Newline newline
\end_inset

CINVESTAV
\begin_inset Newline newline
\end_inset

Guadalajara, Jal, Mexico 
\begin_inset Newline newline
\end_inset

 
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and
\end_layout

\end_inset

 
\begin_inset Flex Author Name
status collapsed

\begin_layout Plain Layout
Andres Mendez Vazquez
\end_layout

\end_inset

 
\begin_inset Flex Author Affiliation
status collapsed

\begin_layout Plain Layout

\shape italic
dept of computer Science
\shape default

\begin_inset Newline newline
\end_inset

CINVESTAV
\begin_inset Newline newline
\end_inset

Guadalajara, Jal, Mexico
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
All vehicule drivers have some implicit profile that help us to recognize
 them.
 The target is to show an alert when a suspicus driving behaviour is detected.
 The main idea is to prevent car theft or a rude behavior of drivers.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
The training data of the project is got from the city of cinnacity which
 give free sources of GPS data and some other variants for public driving
 services.
 This includes street sweepers, trash packers, and snow plows.
 Vehicles are identified by location and asset number.
 The main idea is to use this variables for use machine learning techniques
 for filter , preprocess data and then use random forest to predict the
 behaviour of the the driver.
 Note that for each asset number we assume a diferent driver.
 
\end_layout

\begin_layout Section
Preparing data
\end_layout

\begin_layout Subsection
First data clean up 
\end_layout

\begin_layout Standard
Once downloading the data set of the project, it could be seen that the
 .csv file was completely unsorted , so first of all it was needed to arrange
 them by vehicule ID, and then sort them by time, to do this task it was
 used pandas framework in python3.6 
\begin_inset CommandInset citation
LatexCommand cite
key "b1"

\end_inset

.
 When the data was correctly separated by ID and sorted by date.
 
\end_layout

\begin_layout Subsection
Remove GPS sensor errors
\end_layout

\begin_layout Standard
Then there was ploted the data in a web browser with a python libary [mplleaflet
]
\begin_inset CommandInset citation
LatexCommand cite
key "b2"

\end_inset

.
 After look some maps plots, there has been some GPS outlier data because
 sensor sometimes has huge errors.
 To solve this problem the main idea was to generate a feature that track
 euclidian distance between points, and remove certain points that overstepped
 the bounds of a threshold.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $X=abs(x_{t}-x_{t-1})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Y=abs(y_{t}-y_{t-1})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $D=\sqrt{x_{i}^{2}+y_{i}^{2}}$
\end_inset

 
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centerline{
\end_layout

\end_inset


\begin_inset Graphics
	filename OutlayerMap1.png
	scale 50

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
GPS noisy data, line across the map
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig-1"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To set up the threshold it was set a filter which take batches of 100 samples
 to generate a normal distribution, then it move the maximum likelihood
 to the max value of the batch, and set a threshold of 95% of acceptance.
 So any value that is bigger than 95% likelihood it will be discarded and
 checked as an outlier.
 First this proces generate a gaussian curve in sample N and then we use
 the gaussian filter in N+1.
 So if the upcoming data has not likely data the set split into a new set,
 and the noisy point is removed.
 Then this was made so on with the next batches of 100 samples.
 This help to work with individual files that are shorter and has more likely
 data, and on the other hand, we could used them as training and testing
 data because they belong to the same driver, however the GPS fails.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centerline{
\end_layout

\end_inset


\begin_inset Graphics
	filename likelihood_filter.png
	scale 50

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
100 frames batch with max Likelihood shifted to max value.
 It could be seen that in the next batch is an outlier.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Features Generation
\end_layout

\begin_layout Standard
For the given data has this default features: LATITUDE,LONGITUDE,REASONS,SPEED,
 HEADING,TIME.
 On the other hand this features were not good enought.
 This drives to generate other features that supplement the information,
 some of this generated features are: Distance between points, X_POLAR ,Y_POLAR,
 and Weighted Frequency Domain.
 The first one is the distance of the points of GPS, it is the same used
 for extract outliers.
 Morever the polar cordinates are gotten from a combination of SPEED and
 HEADING(compas split on 16 directions).
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Wind_{\theta}=HEADING_{index}*\frac{2\pi}{16}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $X_{polar}=Speed*Cos(wind_{\theta})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Y_{polar}=Speed*Sin(wind_{\theta})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename polar_and map.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Polar cordantes representation with cleaner data
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
The Weighted Frequency Domain is a measurment of how long it was a vehicule
 in certain place.
 Where 
\begin_inset Formula $f_{s}$
\end_inset

 = average sampling frequency, and we could get if device is ON or OFF withe
 the REASONS feature.
 
\begin_inset CommandInset citation
LatexCommand cite
key "b3"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{equation*} w_f(x_i)=
\backslash
begin{cases}           
\end_layout

\begin_layout Plain Layout

		
\backslash
frac{t_{i+1}-t_i}{f_s} 
\backslash
quad &
\backslash
text{if} 
\backslash
, dist(x_i,x_{i+1}) <= 
\backslash
lambda 
\backslash
wedge 
\backslash
textrm{ON}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

       1 
\backslash
quad &
\backslash
text{otherwise}
\backslash

\backslash
 
\backslash
end{cases} 
\backslash
end{equation*}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PCA
\end_layout

\begin_layout Standard
Once all features are generated the PCA is used to obtain the most relevant
 features of the data.
 In the image below it could be seen that the latitude and longitude variables
 depend on each other so they are highly correlated, which it must be discarded
 because they are not orthogonal and the only thing they do is to give unnecessa
ry information.
 Intead we vould observed that WFD and polar cordenates has lower covariance
 with other varables and between each other.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Covariance_matrix_features_map.png
	lyxscale 50
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Correlation as step to get PCA
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
When the correlation matrix is centerd and the eigenvalues and eingvectors
 are arranged, we could visualize the relevance for each feature.
 This provide a more clear overview of which features should be selected
 and discarded in relation with others ones that may not contribute to much.
 As it was said before the most ortogonals variables was the wfd, and polar
 cordenates, so it be very possible that they are the winners of the PCA.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename PCA_relevance.png
	lyxscale 35
	scale 35

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
PCA relevance
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

 Rember that these polar represenation is composed by the radius as the
 vehicule speed and the turn angle as a compas direction, for instance it
 is not being used the Lat and Lon data, but we may use other strategies
 in the future to make them more useful.
 
\end_layout

\begin_layout Standard
Finally we could test the PCA clasification between two random drivers,
 that has different behavior and routes of driving, we only take the two
 most relevant features that are the polar cordantes.
 As a result it is wanted to see two different clusters well separeted and
 clasified.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename PCA_Clasificaction.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename 3ClustersPCA.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
PCA between Vehicules
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
DBSCAN
\end_layout

\begin_layout Standard
The DBSCAN algorithm will help to determine if two cluster from the PCA
 output are seperable.
 Thhe advantage of this one between K-means is that doesn't be determined
 the number of cluster a priori, also there are not round shaped, and has
 notion of noise.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Map_with_DBSCAN.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
DBSCAN of two different drivers
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
On the other hand it has two hyperparamters for good and not supervised
 clasification.
 Epislon and min num of cluster, which they are looked by bruteforce searching,
 the main idea is to compare one by one driver with a target driver, so
 there are certain hyperparameters wich give higher number of clusters,
 but the may be produce noise them toghter, so we will look for a medium
 solution, and we may need to score this clasification in other way, and
 there is where random forest is used.
 
\end_layout

\begin_layout Subsection
Random Forest
\end_layout

\begin_layout Standard
Random Forest is selected as averaging 15 trees, this was totaly experimental.
 As more trees are added there is not visual difference.
 To find the best split a single tree there was ran multiple times different
 posibilities, and the calculate its variance.
 The one with less variance will be the best fit.
 So this mean de desicion will be the better.
\begin_inset CommandInset citation
LatexCommand cite
key "b5"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Splitree.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Example of one split
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Spliting the target driver in training data and testing data, we have a
 good training over the time with random Forest.
 The main idea is to test in average result of N samples, and append more
 samples over the time.
 At first instance the model is confused to recognized if the driver is
 indeed himself, then as time passes it does better.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align left
\begin_inset Graphics
	filename Overtime.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Random Forest Training
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Mixed Strategy
\end_layout

\begin_layout Standard
Finally it was decided to merge all strategies developed in order to found
 a better perfomance over time.
 So first at all we look to fit better the hypermeters for DBscan clustering.
 To do this we compare our target driver with other drivers, this is done
 passing throught a PCA compression and then running a DBSCAN algorithm
 to look if 2 clusters are distinguishible between them.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename General Logic.jpg
	lyxscale 50
	scale 15

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Strategy 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
The procedure continue until go over all drivers.
 The result of good clusters are saved in a set, and then this one is loaded
 into a Random Forest training.
 For this test we get a score and we follow a semi supervised leraning.
 This procedure is executed over 10,000 with different hypermater trials
 and it was look to find the best match with the best score.
 This was done with multiprocessing programing and paralellism techniques.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ALLstrategies.png
	lyxscale 50
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Results of mixed strategy
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this mixed strategies algorithm the curves starts at 0 an then rise up
 smoother than the one with just random forest.
 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this project we have a classical situation between variance and bias.
 In the first machine learning aproach with just random forest the system
 has higher variance but less bias, and over the mixed trategy it has less
 variance and bias, because DSCAN preselection.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "b1"

\end_inset

 Department of Public Services.
 (2021, July 5).
 Vehicle-GPS-Daa-Department-of-Public-Services.
 Citty of Cincinnati.
 https://data.cincinnati-oh.gov/Efficient-Service-Delivery/Vehicle-GPS-Data-Depart
ment-of-Public-Services/b56d-ydmm
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "b2"

\end_inset

 GitHub - jwass/mplleaflet: Easily convert matplotlib plots from Python
 into interactive Leaflet web maps.
 (n.d.).
 GitHub.
 Retrieved August 2, 2021, from https://github.com/jwass/mplleaflet3.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "b3"

\end_inset

 Wojtusiak, J., & Mogharab Nia, R.
 (2021).
 Location prediction using GPS trackers: Can machine learning help locate
 the missing people with dementia? Internet of Things, 13, 100035.
 https://doi.org/10.1016/j.iot.2019.01.002
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "b4"

\end_inset

 Cai, L., Li, S., Wang, S., & Liang, Y.
 (2017).
 GPS Trajectory Clustering and Visualization Analysis.
 Annals of Data Science, 5(1), 29–42.
 https://doi.org/10.1007/s40745-017-0131-2
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "b5"

\end_inset

 Kumar, V.
 (2019, September 10).
 Random forests and decision trees from scratch in python.
 Medium.
 https://towardsdatascience.com/random-forests-and-decision-trees-from-scratch-in
-python-3e4fa5ae4249
\end_layout

\end_body
\end_document
